Get the dataset through Kaggle.com

go to https://www.kaggle.com/dalpozz/creditcardfraud/data

Download creditcard.csv from "Credit Card Fraud Detection" Dataset and save it on the same file level as jupyter notebook 





Hello and welcome to this machine learning tutorial presented by Eduonix. My name is Brendan, and I will be your instructor for this project. In this lesson we are actually going to be doing credit card fraud detection using several methods of anomaly detection from the sklearn package. We are going to be using a Local Outlier Factor to calculate anomaly scores, as well as an Isolation Forest algorithm. These two algorithms will comb through our dataset of almost 280,000 credit card transactions and predict which ones are fraudulence. Here is an example data point, and the results that we can expect to achieve with the networks that we are going to train. In our dataset, we have 30 parameters, we have the time and the amount of the transaction as well as 28 other features that are result of a PCA dimensionality reduction in order to protect the identity and sensitive information involved with these credit card transactions. Here is our trained isolation for forest algorithm, and these are results that you can expect to get. As you see here, this Class of 1, 1 means that this was a fraudulent transaction, whereas in our dataset, 0 would mean it's a valid. This network is going to predict -1 for outlier or a value of 1 for an inlier. And as we can see, it correctly predicts that this is an outlier or a fraudulent transaction. So, some Python knowledge is recommended. However, I will be taking you through each and every individual steps involved, so there is no worries about getting lost or falling behind. I hope that you can learn some valuable information from this tutorial, where we'll be using Jupyter Notebooks to develop this Python application. It has some valuable lessons about preprocessing datasets as well as the deployment of multiple anomaly detection algorithms being our Local Outlier Factor and our Isolation Forest algorithm. I hope you continue to listen and enjoy the project. [No audio]



Hello, and welcome to this tutorial on machine learning by Eduonix. In this project, we're going to be performing credit card fraud detection by using several different anomaly detection methods. So I'm really excited to dive in because this is such an incredible application of anomaly detection or outlier detection, and is an interesting part of unsupervised machine learning. So let's go ahead and dive right in. For this project, we're going to be using a dataset that is hosted on kaggle.com. So this is the credit card fraud detection dataset. It's got an open source data base license, so it's free to us to use. Unfortunately, it's behind a, you got to get an account on Kaggle to go ahead and download this, I'm hoping that we can host it on the Eduonix website, and you can get it along with the project. However, it's just as simple sign up and provide an email and then you'll be able to access this. So I've already gone ahead and did that. And I downloaded this file, it's just a simple CSV file. So you see it's here in my Tutorial folder, so that I will be able to access that there. So go ahead and pause the video. And whether it's from the Eduonix website, or from this kaggle website right here, create an account and download that CSV file, it's going to come as a zip and extract it and place it in whichever folder that you are going to be completing this project in. Okay, so, once that's completed, we can go ahead and just like the previous projects, we are going to be using conda to launch Jupyter Notebooks and programming our project in Python through Jupyter Notebooks, because that is a great way to make it transferable and work cross platform. So I'm using Windows. So if you're on a Windows machine, you'll be able to follow along exactly. However, if you're on Linux or a macOS, you may have to change a few things to launch your Jupyter Notebook appropriately. But for Windows, go ahead and just type jupyter notebook and that will open up the notebook in your web browser. [No audio] As per usual, we are going to be using NumPy, pandas, matplotlib, and sklearn. So, if you don't have those packages already installed, go ahead and do conda install, whatever the package name is. However, if you have been following along with the projects that we have been completing so far, then you will likely have all of these installed already. But we'll go ahead and do an import check to make sure that we're all running the same versions of these difference. [No audio] And here I was in the wrong folder. So I'm going to go into my Tutorial folder. Remember, wherever you type this Jupyter Notebook, opens up the folder that you are in currently in your terminal. Okay, so now that I'm here in my Tutorial folder, I'm going to go ahead and open up a new Python Notebook or Jupyter Notebook, and we can name this something appropriate, [No audio] Credit Card Fraud Detection, because that is what we are going to be doing today. Okay, so let's start. And we'll do generic imports of all of the libraries that we need, and we'll also print off the version so that we know we're using the same ones. As always, we'll do an import sys to get our Python version. We're going to be using numpy, [No audio] pandas again, import matplotlib, import, and we're going to need seaborn once more to do a correlation matrix, we also need scipy. Okay, so let's go ahead and print those off. And we'll do a nice little format here. Format is a great way to substitute variables into strings in Python. [No audio] So whenever I have to substitute a variable into a string, I often go, I usually always go with this .format method. [No audio] And you can do multiple variables, it all just depends what you need. I'm going to Ctrl C and copy this a couple of times to speed up this process here. So we have numpy, let's make this one pandas, and we'll switch this here. [No audio] We are going to need, oh, and I accidentally clicked enter, matplotlib, [No audio] we'll get this sorted out, seaborn. [No audio] And then the last one, scipy. [No audio] I was actually going to wait to import the sklearn until we were doing the machine learning steps, but let's go ahead and do that now actually. [No audio] Okay, oh, and I'm going to have an error here. There we go. So here are the packages that I am using, Python 2.7 as always, and then these packages and versions here. So make sure you have up-to-date versions of these packages, and everything should run appropriately. Alright, but now let's move on. Because we don't need the overall packages, we need some more specific packages. [No audio] So we'll dive into that. What I mean by this is we're going to use numpy and shrink things down, we'll use it as np. [No audio] Similarly, we'll do pd for pandas. [No audio] We need pyplot for our graphical interface. And we'll use it as plt. Now we'll import seaborn as sns. So go ahead and click Shift Enter here, and those are all good. And so if you have hit an error in one of these steps, and you probably don't have one of these packages installed, or modules installed, you can go back to your terminal, or open up a new terminal since the Jupyter Notebook is running in this one, and type conda install, and then whatever package you are missing, as long as conda is in your path variables that will download and install the appropriate module that you need, and then you should be able to come back here and successfully import it. [No audio] But, as long as that's all going and up and running, we are ready to move on. So let's load the dataset. [No audio] We're going to use Pandas for this. So, if you were successful, and you got the dataset downloaded, and it is in your same folder as your Jupyter Notebook file is now, then all it's going to take to get this into our notebook is a read_csv function, [No audio] creditcard.csv, and that's going to pull this in as a pandas DataFrame. [No audio] So let's go ahead and click Shift Enter and make sure this works, [No audio] and we're thinking because this is a pretty big csv file, but we were good, we were successful. As soon as this number pops up, you know you are good to go, and it looks like it has it. So let's start exploring the dataset a little bit. So we know what we're working with. The first thing I like to do is a data.columns, so we know what is included in the dataset. Okay, so it looks like we have about 31 different columns going from Time, all the way to Amount and Class. So here we have V1 through V28. And these are actually the result of a PCA dimensionality reduction that was used in order to protect sensitive information in this dataset. For example, we don't want to expose the identity of the individual who made the credit card transaction. We also don't want to expose stuff like location. But this is a time in a separation from previous transactions and amounts. And then a Class, our Class here is going to be a 0 for, it's a valid normal credit card transaction, and then 1 is going to mean a fraudulent transaction. But let's go ahead and learn a little bit more about that. So let's do a print(data.shape). So we know what's here. Okay, so we have 284,000 credit card transactions with 31 columns, all of this information for each transaction. Let's do a print(data.describe), and we lost our print function here. [No audio] Get the correct parentheses, and this will give us useful information about each column. So this gives us the mean, min, max, etc., and count for each column. So you see here, the count is the same for each of these parameters. So that means that we're not missing any data, so that's helpful. [No audio] This is formatted weird. It's not showing us the middle V's. That's what these ... mean here. The class though, is the important part. So we have 284,000 of these, we have a max of 1, that's the fraud, and we have a min of 0, that's the standard. If you see this mean, this looks like it's really close to 0. So that must mean we have way more valid transactions than we do fraudulent transactions. So we're going to have to account for that as we go on. One thing I'm also going to do, since this is such a large dataset. In order to save on time and computational requirements, I am going to sample only a fraction of this data set. So instead of using all 280,000, I'm going to do data = data.sample [No audio] (frac = 0.1). So I'm only going to take 10% of the data. And just so that we have the same data, we're going to define the random_state here. And then I'm going to do print data.shape, just to make sure that worked. Okay, so now it's 284,000, we have 28,481, still have all of our columns, but this is a much more reasonably sized dataset to work with. Now, if we used all 284,000 of these, we'd probably get better results. However, for the sake of computational requirements, I'm going to go ahead and cut this down right now, so that we, we have more manageable data to work with. So let's keep exploring our dataset. We've imported our CSV file, we've looked at each of the columns and the column names, and the distributions. Another way to do that visually is going to be a Plot, a histogram of each parameter. So to do that, it's really easy with the pandas DataFrame, where you're going to do, data.hist, and I'm going to define a figsize here to make it a little more pretty. [No audio] And then we need a plt.show since this is going to be a pyplot, works hand in hand with matplotlib, and pandas. And if I go ahead and click Shift Enter there, we should be able to pull this up, [No audio] after it gets done thinking, okay, here we go. So here is all of the histograms. And so this looks like most of our v's are clustered right around 0 with some fairly large outliers, or maybe no outliers, in regards to this one. The interesting thing here is, again we see that we have very few one values or fraudulent transactions in comparison to our valid transactions. So that's kind of surprising, although it makes sense since this is real world data. But let's go ahead and actually calculate the number of fraudulent cases that we have, and the number of valid cases that we have, so we can get an outlier fraction that is going to go into our future methods or anomaly detection methods. So to do that, we're going to just start with a comment here. [No audio] So, Fraud is going to be equal to data, and we can index this by saying just data and 'Class' [No audio] and bracket, where Class = 1. So that is a fraudulent case, and we'll have a Valid, is going to be equal to the data. We can index this with the 'Class' again. However, this time we want equals to 0, these are going to be the valid transactions. Okay. And we're using this to calculate a percentage of fraudulent cases to valid cases. So we can do an outlier_fraction, is going to be equal to the len(Fraud) divided by. Now we got to be careful here. If we don't use a float here, it's going to round us to an integer which would round us to 0 since this is going to be really low. So what we need to do to carry our decimal points is type float to turn this into a float, which is the type of data, and then our (len(Valid)). So this is going to be the number of fraudulent cases divided by the number of valid cases with decimal points. So let's print this out. [No audio] And I'm also going to do, print out the number of 'Fraud Cases', [No audio] and we'll make this nice, we'll use another format, because it's always good practice. [No audio] And we'll just do len(Fraud) here. Okay, and we'll also do a print('Valid Cases: [No audio] ' .format(len(Valid)). Okay, so we'll go ahead and click Shift Enter here. So, we actually see that we only have about 0.17% of our databases, fraudulent cases. And that's a total of 49 fraudulent cases, and 28,000 valid cases. So we have a huge disparity here between the fraudulent cases and the valid transactions. So this is going to be harder to predict, but it makes it a, it's important to carry all this information through, because if you have an overrepresentation of fraudulent cases, in the dataset that you're using to train your algorithms, you're going to end up predicting more fraud than there actually is. So it's important that we consider this underlying percentage of, of fraudulent cases, this outlier fraction, before going into actually building our networks. One more thing that we should do is build a Correlation matrix to see if there is any strong correlations between different variables in our dataset. This is going to tell us whether or not we need to remove things like, in previous projects it was the id of our datasets, we don't have an id here, it's also going to tell us if there are strong linear relationships, which we could then use different linear methods to predict these, it's also going to show us which features are important for the overall classification. So here is our correlation matrix and the pandas DataFrame, which is the type our dataset is in right now, makes this really easy with the .corr function here. And then we just simply do a pyplot figure. So we'll have plt.figure(figsize) to make this nicer again. [No audio] And we're also going to use the seaborn here. So this is what we're going to do, the sns heatmap. [No audio] And this is going to turn our correlation matrix into a very nice visual display, that is easy to read. [No audio] And plt.show once again, and Shift Enter to pull this up. And here we go. So here's our correlation matrix with the heatmap. So if you see, we have a lot of values right here really close to 0. So there is not, there isn't strong relationships between our different V parameters, the V1 through V28. Most of them are fairly unrelated to the others. However, what we do care about is the Class. So we see there is some variations in the relationships between the different parameters and our Class here. So, the lighter ones are going to be a positive correlation, whereas negative would be a strong negative correlation. So we see maybe V17, and V11, V11 stronger positive, whereas V17 would be a stronger negative correlation. There isn't a strong correlation between Amount, and whether or not it was fraudulent, or Time, and whether or not it was fraudulent. That could be some interesting information to take away. We don't see many one to one correlations here in our correlation matrix. So that's good, we don't need to pull out any of our columns before we dive into doing our actual machine learning. But, before we actually get started with that, we need to format our dataset slightly. So let's go ahead and do that. [No audio] So we need to get all of our columns from the DataFrame. To do that, we're going to do columns = data.columns.tolist. So that'll generate a list of columns. And then we want to Filter the columns to remove data we do not want. So in this case, there's only going to be one that we're pulling out, [No audio] and that is going to be our "Class". [No audio] It would be very easy to predict which ones were fraudulent if we told our network which ones are fraudulent. So, this is unsupervised learning since it's anomaly detection. So we don't want the labels to be fed to our networks ahead of time. [No audio] So we want to store the variable we're predicting on as well, and that's going to be the target here. And the target, once again, is going to be "Class". That's what we're trying to predict. So we can have our X data, what we're going to do is the data, and this is going to be the columns, which we pulled the class out of, and we can have Y = data. And this is going to be the target, so only the Class. So let's go ahead and print the shapes, [No audio] so that we know what we are working with, and if everything worked correctly, [No audio] we'll be able to see that here. Okay, go ahead and click Shift Enter here. So, indeed it did work. We now have 30 columns in our X, which was everything except our class label. And then our Y is a one-dimensional array that has the class labels for all 28,000 samples from our dataset. So that's exactly what we wanted. And everything is set up now to go ahead and start building our networks. We're going to use an Isolation Forest algorithm as well as a Local Outlier Factor algorithm to try to do anomaly detection on this dataset. However, that is going to be in the next video. I'm going to stop this one here, since we have successfully imported, preprocessed, and explored our dataset, we have put ourselves in a position to pick correct machine learning algorithms and methods and produce results that are going to be meaningful and accurate. So, keep following on in the second video, and I hope everything went well up until this point. Thank you very much.




Hello, and welcome back to this tutorial on credit card fraud detection using multiple anomaly detection methods programmed in Python through Jupyter Notebooks. So in the last video, we successfully built and set up our dataset, which included 284,000 data points, but we went ahead and downsampled that a little bit, so we would have a more reasonable dataset to work with. And that fraction I did was about 10%. So we've 28,000 credit card transactions, a total of 49 anomaly cases, and 28,432, valid credit card transactions. And we went ahead and separated that into an X, which is the data with all of the columns that we are interested in, and then a Y, which is the target column or Class, 0 being valid transaction and a 1 being a fraudulent credit card transaction. So now we are in a position to go ahead and move on to actually fitting this data and trying to predict which ones are outliers. So, as per usual, we need to import the packages that we are going to be using, and these are going to come from sklearn. So, the first ones are metrics that we are going to use to determine how successful we are in our outlier detection. So we'll do an accuracy_score and a classification_report. [No audio] And I made a spelling error here, so let me go ahead and correct that. And then from an ensemble method, we are going to import the IsolationForest. And we'll talk about what and how these, these methods work in a sec. We're also going to use the LocalOutlierFactor. So these are two common anomaly detection methods from the sklearn package. And, these are commonly used, you might also see things like a support vector machine used for outlier detection, that takes a little bit longer to train in this case. So with 28,000 data points, actually computing the support vectors to build a machine like that would take a while. So this is why I'm only doing the IsolationForest and the LocalOutlierFactor. Okay, so, let's talk about these methods for a sec before we get started. The LocalOutlierFactor is an unsupervised outlier detection method, and this goes ahead and it calculates the anomaly score of each sample, and we call it the LocalOutlierFactor. So it measures the local deviation of density of a given sample with respect to its neighbors. It is local in that anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. So we're talking about neighbors here, and this is going to be determined in the same way as the k-nearest neighbors method. So, we're actually doing something very similar. However, we're calculating an anomaly score based off those neighbors. The IsolationForest algorithm is a little bit different, it's going to return the anomaly score of each sample using this IsolationForest method. So it does that and it isolates the observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. So we're going to have all the different columns here, could be considered a feature. Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node. So if you're like me, that doesn't make a lot of sense to you. However, it's more easily understood if we go into what exactly that is, that means. So, this path length averaged over a forest of such these random trees is a measure of normality and our decision function. So random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for a particular sample, they are highly likely to be anomalies. So this is a combination of the random forest algorithms, and it's doing that to isolate points, which have these shorter path lengths, or are more likely to be anomalies. So if you want to read more about these methods, I encourage you to do so. However, for now, we'll go ahead and just dive into programming them up in Python, and then seeing what type of results they produce. In machine learning it's really important that you understand the algorithm, say you are using, because you need to pick the algorithm that is going to be the most successful. A lot of the times it's a good idea to compare multiple methods. For example, we're comparing these two in this tutorial. However, even narrowing it down to two different machine learning methods is going to require a lot of foresight. So, it's just something to consider. So to start, I'm going to define a random state, so that we're all on the same page here, and then I'm going to define the outlier detection [No audio] methods. So this is where we're actually going to import these, these different algorithms. [No audio] So I'm going to put this into a dictionary of classifiers. [No audio] So what I'm going to have is, I'm going to have the first one, an Isolation Forest. [No audio] And this is simply type IsolationForest with no space, and then we have to define a couple of parameters. So, the first one we're going to have is the max_samples, and we're just going to put this as the len(X). So the max_samples is the total number of samples that we have, it's going to have a contamination, which is the number of outliers we think there are, and we know this is actually the outlier_fraction that we calculated earlier, when we were going through our dataset. So we went ahead and we calculated that up here, simply the number of fraudulent cases over the number of valid credit card transactions here. Okay, we need one more, and that is going to be the random_state that we defined above. So we'll just say = state. Alright. So that's the first one. But we also have the Local Outlier Factor. [No audio] So LocalOutlierFactor. And this has a couple parameters as well. So the n_neighbors to consider, this is what goes into the k-nearest neighbors method that it uses, we're just going to set this as 20, 20 is kind of a default or a standard, the higher the percentage of outliers in your dataset, the higher you're going to want to make this number. So I might even try to play around with this a little bit and lower this down to see if it produces different results. And once again, we need the contamination. [No audio] And this is once again equal to our outlier_fraction, let me give some spaces. [No audio] There we go. So that's our, our dictionary of our different classifiers. Let's go ahead and do a Shift Enter here to make sure that everything imports correctly, and that we're defining these methods correctly as well. And it looks like we are. So yes, it successfully went ahead and got that. So we are good to go to move on. So let's actually fit the model. [No audio] So this is where the fun begins. But, first, we are going to have to, we're going to have to define a variable called the n_outliers. And this is going to be equal to the len(Fraud). This will be referenced a couple times, so we're just going to go ahead and define this ahead of time. And what we're going to do is we're going to do a for loop through the two different classifiers that we defined above. So, we can say for i, and what we're going to do here is we're going to enumerate our, our list of classifiers, so that we can cycle through them. [No audio] And this is dictionary, so we can rep, we can index it in this way with the .items. And you know it's a dictionary, because we use these brackets here. [No audio] Okay, so we need a : here to round out our for loop, and so we can go ahead and start defining things now. [No audio] So we're going to have to do two different steps here actually, because it's a little bit different if we're using the LocalOutlierFactor versus our IsolationForest. So what I'm going to do is I'm going to do if clf_name is "Local Outlier Factor", then I'm going to do the following. That is going to be our, we're going to do a wide prediction here. And so for the Local Outlier Factor, you can do this convenient function, which is called the fit_predict(X). So it is going to fit the X data, which was, and then, which was all of our columns without the class, and then it's also going to predict the labels for those values. So let's get the scores here, scores_pred. This is going to be clf.negative_outlier_factor. So that'll come in handy later. And so we'll move on here. So other, if it's not the Local Outlier Factor, in other words, it's our Isolation Forest, we are going to do clf.fit(X). So we have just the .fit function here. And then we're going to do scores_pred is going to be the clf.decision_function that it generates off of X, and then finally, y_predict is going to be the clf.predict(X). Okay. So that should give us everything that we need. It's doing two different fitting methods, depending on whether or not it's the Local Outlier Factor, it's going to do a fit_predict, and it's doing a normal fit and a later predict if we're using our Isolation Forest. Okay, so there is one thing we have to do though, before we can move on. The results, these y_pred values that we're going to get back are going to give us a -1 for an outlier and a 1 for an inlier. So that is useful information, but we need to process it a little bit before we can compare it to our class labels. Because if you remember, our class labels are either 0 for valid and 1 for fraudulent. So that's why we have to change this a little bit. So we want 0 for valid, 1 for fraud. So we can do that by simply pulling up our y_pred and then indexing them based off the y_pred is equal to 1. And then what we can do is we can reassign this to 0. So this is taking all of our inliers and classifying them as 0 or a valid credit card transaction. We're also going to do y_pred indexed by our y_pred equals -1. So our outliers here, the ones that we think don't belong with the rest of the transactions, we are going to classify these as our fraudulent transactions. Okay, so that should be good to go there. What we want to do now, is we want to calculate the number of errors. So what we need to do is a comparison to y. If you remember, y is our target. So y is the values of fraudulent or value, or valid 0 or 1 for each individual case. So what we can do is we can do the n_errors here. And this is going to be equal to our y_pred when it does not equal Y. And what we're going to do is we're going to go ahead and sum these. So that'll give us a total n_errors. Finally, what we want to do here is we want to Run the classification metrics, because this is going to tell us much more useful information. [No audio] So what we want to print out here is going to be this first part. So we want to give us a name and the n_errors here. So to do that we're going to do a .format. We'll have a clf_name, and then n_errors. [No audio] Okay, so that should print out the name for us. Alright, and then we want the accuracy_score here. So this is one of the metrics that we imported above, score, and we're going to do a Y, the values that we want and our y_pred what we think they are. Alright, and then we're also going to print out a classification_report. And we'll see very quickly why this classification_report is going to be important. So once again, comparing Y to what we predict our y. So it looks like everything is good to go. We initialized our classifiers up above. But let's go ahead and do a Shift Enter here and see if this is indeed going to work. [No audio] So we're thinking, and here comes our first one. So we have a Local Outlier Factor here. And we had 97 Total errors, so relatively high. But, if you see, we were 99.659% accurate, so very accurate. But you'll see if you look down here at our precision, recall, and f1-score, you'll see that we're not quite as good as we think. So what this is saying is, for class 0, we had a precision of 100%. But for class 1, we only had 0.02. So that actually is not very good. So that means that we have very few actual fraudulent cases that are getting labeled as fraudulent cases, I think we only got about one of them correct here. So precision counts for false positives, which we were assigning a bunch of the valid credit card transactions as positive, as well, and the recall accounts for false negatives, and so not good with false positives or false negatives at all. And the f1-score is a combination of those. However, our isolation for us was a little bit better. So we had 99.75% accuracy, but we had a precision of 30%. So that's a lot better than 0.2. But still, we're only correctly identifying about 30% of our actual fraudulent cases. So we do have a lot of false positives as well. So we're going to be frustrating our customers, because we're always calling them asking, Did you make this transaction, [Laughter], but we have the recall of 1 percentage point better, so not good as well. So we had a couple of false negatives, we should have classified a few as fraudulent, when we did no such thing. However, our f1-score, better for the Isolation Forest, than the Local Outlier Factor. So essentially this dataset was sufficiently complex, our random forest method or random forest-based method was able to produce better results. So 30% of the time, we are going to detect the fraudulent transaction. So, as long as the criminals in our case make four transactions, [Laughter], statistically, we will find them every time. So there are better methods out there than this. Since we do have labels, you can use things such as neural networks. However, this is an interesting dataset to explore with anomaly detection. Again, we could probably improve our results if we went back and we took a larger sample of our data, we have 284,000 cases here. However, that is going to be computationally expensive, as it is it already took probably 20 seconds to do the Isolation Forest method here. So, if you can imagine increasing that semi-exponentially, you're going to really increase the computational requirements of this program. So that is why I cut it down. Well, thank you for following along. I hope that you were able to learn a lot of new information. In this tutorial, we went over importing a CSV dataset, preprocessing that dataset, as well as exploring the data and describing the data, so that we knew what we were working with and we knew what information we had. We did histograms to see if there was any unusual parameters. We went ahead and we separated into fraudulent and valid, determining the outlier fraction, which was very low, less than 1% here, 0.17% actually. We did a correlation matrix to show which parameters were important for our class, and we saw some variations here, so we knew that we'd be able to make decent predictions. We separated these based off of our target parameter, which was the class, and then we used two different methods, the Isolation Forest and the Local Outlier Factor to do anomaly detection on this dataset. And this was also a valuable lesson in the importance of understanding your data and understanding precision and recall, because we showed that we had a 99.65% accuracy, but we were only accurate because there are so many more valid cases than fraudulent cases. So we were very bad at actually detecting the fraudulent cases with our Local Outlier Factor. However, with the Isolation Forest, we achieved almost 30% in detection of those outliers or those fraudulent cases, which still isn't great, but it is a significant step in the right direction. Once again, thank you for following along. I hope you enjoy the future projects. Thank you very much. [No audio]

